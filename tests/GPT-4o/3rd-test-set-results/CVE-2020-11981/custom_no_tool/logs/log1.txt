time="2025-11-12T20:06:59+01:00" level=warning msg="/home/gabriele/thesis-project/Agents-for-Vulnerable-Dockers-and-related-Benchmarks/dockers/CVE-2020-11981/custom_no_tool/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network custom_no_tool_default  Creating
 Network custom_no_tool_default  Created
 Volume custom_no_tool_postgres_data  Creating
 Volume custom_no_tool_postgres_data  Created
 Container custom_no_tool-postgres-1  Creating
 Container custom_no_tool-redis-1  Creating
 Container custom_no_tool-redis-1  Created
 Container custom_no_tool-postgres-1  Created
 Container custom_no_tool-airflow-worker-1  Creating
 Container custom_no_tool-airflow-webserver-1  Creating
 Container custom_no_tool-airflow-scheduler-1  Creating
 Container custom_no_tool-airflow-worker-1  Created
 Container custom_no_tool-airflow-webserver-1  Created
 Container custom_no_tool-airflow-scheduler-1  Created
 Container custom_no_tool-postgres-1  Starting
 Container custom_no_tool-redis-1  Starting
 Container custom_no_tool-postgres-1  Started
 Container custom_no_tool-redis-1  Started
 Container custom_no_tool-airflow-scheduler-1  Starting
 Container custom_no_tool-airflow-worker-1  Starting
 Container custom_no_tool-airflow-webserver-1  Starting
 Container custom_no_tool-airflow-worker-1  Started
 Container custom_no_tool-airflow-scheduler-1  Started
 Container custom_no_tool-airflow-webserver-1  Started


sudo docker logs b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918 --details
STDOUT:  DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 .
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:05,359] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 5, 347010, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:05,520] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:08,053] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 8, 41517, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:08,163] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:10,149] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 10, 138058, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:10,273] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:12,566] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 12, 556454, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:12,713] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:15,236] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 15, 227363, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:15,346] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:18,622] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 18, 612829, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:18,714] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 [2025-11-12 19:07:23,663] {cli_action_loggers.py:107} WARNING - Failed to log action with (psycopg2.errors.UndefinedTable) relation "log" does not exist
 LINE 1: INSERT INTO log (dttm, dag_id, task_id, event, execution_dat...
                     ^
 
 [SQL: INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (%(dttm)s, %(dag_id)s, %(task_id)s, %(event)s, %(execution_date)s, %(owner)s, %(extra)s) RETURNING log.id]
 [parameters: {'dttm': datetime.datetime(2025, 11, 12, 19, 7, 23, 653769, tzinfo=<Timezone [UTC]>), 'dag_id': None, 'task_id': None, 'event': 'cli_scheduler', 'execution_date': None, 'owner': 'airflow', 'extra': '{"host_name": "b5394411bcee", "full_command": "[\'/home/airflow/.local/bin/airflow\', \'scheduler\']"}'}]
 (Background on this error at: http://sqlalche.me/e/f405)
   ____________       _____________
  ____    |__( )_________  __/__  /________      __
 ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
 ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
 [2025-11-12 19:07:23,753] {__init__.py:51} INFO - Using executor CeleryExecutor
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 
 DB_BACKEND=postgresql+psycopg2
 DB_HOST=postgres
 DB_PORT=5432
 

STDERR:  Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 5, 521531, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 5, 521542, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 8, 164027, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 8, 164036, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 10, 274141, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 10, 274155, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 12, 714190, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 12, 714201, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 15, 347247, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 15, 347263, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 18, 715260, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 18, 715270, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)
 Traceback (most recent call last):
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 psycopg2.errors.UndefinedTable: relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/airflow/.local/bin/airflow", line 37, in <module>
     args.func(args)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 75, in wrapper
     return f(*args, **kwargs)
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1040, in scheduler
     job.run()
   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 215, in run
     session.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
     self.transaction.commit()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 503, in commit
     self._prepare_impl()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
     self.session.flush()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2496, in flush
     self._flush(objects)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2637, in _flush
     transaction.rollback(_capture_exception=True)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 69, in __exit__
     exc_value, with_traceback=exc_tb,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2597, in _flush
     flush_context.execute()
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
     rec.execute(self)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
     uow,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
     insert,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
     statement, params
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 984, in execute
     return meth(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
     return connection._execute_clauseelement(self, multiparams, params)
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1103, in _execute_clauseelement
     distilled_params,
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1288, in _execute_context
     e, statement, parameters, cursor, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1482, in _handle_dbapi_exception
     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 178, in raise_
     raise exception
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1248, in _execute_context
     cursor, statement, parameters, context
   File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
     cursor.execute(statement, parameters)
 sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "job" does not exist
 LINE 1: INSERT INTO job (dag_id, state, job_type, start_date, end_da...
                     ^
 
 [SQL: INSERT INTO job (dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s) RETURNING job.id]
 [parameters: {'dag_id': None, 'state': 'running', 'job_type': 'SchedulerJob', 'start_date': datetime.datetime(2025, 11, 12, 19, 7, 23, 754607, tzinfo=<Timezone [UTC]>), 'end_date': None, 'latest_heartbeat': datetime.datetime(2025, 11, 12, 19, 7, 23, 754617, tzinfo=<Timezone [UTC]>), 'executor_class': 'NoneType', 'hostname': 'b5394411bcee', 'unixname': 'airflow'}]
 (Background on this error at: http://sqlalche.me/e/f405)




sudo docker inspect b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918[
    {
        "Id": "b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918",
        "Created": "2025-11-12T19:06:59.587103298Z",
        "Path": "/usr/bin/dumb-init",
        "Args": [
            "--",
            "/entrypoint",
            "scheduler"
        ],
        "State": {
            "Status": "running",
            "Running": true,
            "Paused": false,
            "Restarting": false,
            "OOMKilled": false,
            "Dead": false,
            "Pid": 8550,
            "ExitCode": 0,
            "Error": "",
            "StartedAt": "2025-11-12T19:07:30.36272384Z",
            "FinishedAt": "2025-11-12T19:07:24.168274395Z"
        },
        "Image": "sha256:b67062e5c67906391f7023b1c0ec7b51f8d4d4be1230e96c1e375d98e696f02a",
        "ResolvConfPath": "/var/lib/docker/containers/b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918/resolv.conf",
        "HostnamePath": "/var/lib/docker/containers/b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918/hostname",
        "HostsPath": "/var/lib/docker/containers/b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918/hosts",
        "LogPath": "/var/lib/docker/containers/b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918/b5394411bcee34c65a9cf2f852dbdcb318a71e8986adbd02ae0cdd7ca0f47918-json.log",
        "Name": "/custom_no_tool-airflow-scheduler-1",
        "RestartCount": 7,
        "Driver": "overlayfs",
        "Platform": "linux",
        "MountLabel": "",
        "ProcessLabel": "",
        "AppArmorProfile": "",
        "ExecIDs": null,
        "HostConfig": {
            "Binds": [
                "/home/gabriele/thesis-project/Agents-for-Vulnerable-Dockers-and-related-Benchmarks/dockers/CVE-2020-11981/custom_no_tool/dags:/usr/local/airflow/dags:rw"
            ],
            "ContainerIDFile": "",
            "LogConfig": {
                "Type": "json-file",
                "Config": {}
            },
            "NetworkMode": "custom_no_tool_default",
            "PortBindings": {},
            "RestartPolicy": {
                "Name": "always",
                "MaximumRetryCount": 0
            },
            "AutoRemove": false,
            "VolumeDriver": "",
            "VolumesFrom": null,
            "ConsoleSize": [
                0,
                0
            ],
            "CapAdd": null,
            "CapDrop": null,
            "CgroupnsMode": "private",
            "Dns": null,
            "DnsOptions": null,
            "DnsSearch": null,
            "ExtraHosts": [],
            "GroupAdd": null,
            "IpcMode": "private",
            "Cgroup": "",
            "Links": null,
            "OomScoreAdj": 0,
            "PidMode": "",
            "Privileged": false,
            "PublishAllPorts": false,
            "ReadonlyRootfs": false,
            "SecurityOpt": null,
            "UTSMode": "",
            "UsernsMode": "",
            "ShmSize": 67108864,
            "Runtime": "runc",
            "Isolation": "",
            "CpuShares": 0,
            "Memory": 0,
            "NanoCpus": 0,
            "CgroupParent": "",
            "BlkioWeight": 0,
            "BlkioWeightDevice": null,
            "BlkioDeviceReadBps": null,
            "BlkioDeviceWriteBps": null,
            "BlkioDeviceReadIOps": null,
            "BlkioDeviceWriteIOps": null,
            "CpuPeriod": 0,
            "CpuQuota": 0,
            "CpuRealtimePeriod": 0,
            "CpuRealtimeRuntime": 0,
            "CpusetCpus": "",
            "CpusetMems": "",
            "Devices": null,
            "DeviceCgroupRules": null,
            "DeviceRequests": null,
            "MemoryReservation": 0,
            "MemorySwap": 0,
            "MemorySwappiness": null,
            "OomKillDisable": null,
            "PidsLimit": null,
            "Ulimits": null,
            "CpuCount": 0,
            "CpuPercent": 0,
            "IOMaximumIOps": 0,
            "IOMaximumBandwidth": 0,
            "MaskedPaths": [
                "/proc/asound",
                "/proc/acpi",
                "/proc/interrupts",
                "/proc/kcore",
                "/proc/keys",
                "/proc/latency_stats",
                "/proc/timer_list",
                "/proc/timer_stats",
                "/proc/sched_debug",
                "/proc/scsi",
                "/sys/firmware",
                "/sys/devices/virtual/powercap"
            ],
            "ReadonlyPaths": [
                "/proc/bus",
                "/proc/fs",
                "/proc/irq",
                "/proc/sys",
                "/proc/sysrq-trigger"
            ]
        },
        "GraphDriver": {
            "Data": null,
            "Name": "overlayfs"
        },
        "Mounts": [
            {
                "Type": "bind",
                "Source": "/home/gabriele/thesis-project/Agents-for-Vulnerable-Dockers-and-related-Benchmarks/dockers/CVE-2020-11981/custom_no_tool/dags",
                "Destination": "/usr/local/airflow/dags",
                "Mode": "rw",
                "RW": true,
                "Propagation": "rprivate"
            }
        ],
        "Config": {
            "Hostname": "b5394411bcee",
            "Domainname": "",
            "User": "airflow",
            "AttachStdin": false,
            "AttachStdout": true,
            "AttachStderr": true,
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow",
                "AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0",
                "AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres:5432/airflow",
                "AIRFLOW__CORE__EXECUTOR=CeleryExecutor",
                "PATH=/home/airflow/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "LANG=C.UTF-8",
                "GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
                "PYTHON_VERSION=3.6.10",
                "PYTHON_PIP_VERSION=20.0.2",
                "PYTHON_GET_PIP_URL=https://github.com/pypa/get-pip/raw/d59197a3c169cef378a22428a3fa99d33e080a5d/get-pip.py",
                "PYTHON_GET_PIP_SHA256=421ac1d44c0cf9730a088e337867d974b91bdce4ea2636099275071878cc189e",
                "PYTHON_BASE_IMAGE=python:3.6-slim-buster",
                "AIRFLOW_VERSION=1.10.10",
                "DEBIAN_FRONTEND=noninteractive",
                "LANGUAGE=C.UTF-8",
                "LC_ALL=C.UTF-8",
                "LC_CTYPE=C.UTF-8",
                "LC_MESSAGES=C.UTF-8",
                "PIP_VERSION=19.0.2",
                "AIRFLOW_UID=50000",
                "AIRFLOW_GID=50000",
                "AIRFLOW_HOME=/opt/airflow",
                "AIRFLOW__CORE__LOAD_EXAMPLES=false"
            ],
            "Cmd": [
                "scheduler"
            ],
            "Image": "apache/airflow:1.10.10",
            "Volumes": null,
            "WorkingDir": "/opt/airflow",
            "Entrypoint": [
                "/usr/bin/dumb-init",
                "--",
                "/entrypoint"
            ],
            "OnBuild": null,
            "Labels": {
                "com.docker.compose.config-hash": "438a8e4811276a71184845edda036b4ee4cd848377e9def0694832d3a3eb5776",
                "com.docker.compose.container-number": "1",
                "com.docker.compose.depends_on": "postgres:service_started:false,redis:service_started:false",
                "com.docker.compose.image": "sha256:b67062e5c67906391f7023b1c0ec7b51f8d4d4be1230e96c1e375d98e696f02a",
                "com.docker.compose.oneoff": "False",
                "com.docker.compose.project": "custom_no_tool",
                "com.docker.compose.project.config_files": "/home/gabriele/thesis-project/Agents-for-Vulnerable-Dockers-and-related-Benchmarks/dockers/CVE-2020-11981/custom_no_tool/docker-compose.yml",
                "com.docker.compose.project.working_dir": "/home/gabriele/thesis-project/Agents-for-Vulnerable-Dockers-and-related-Benchmarks/dockers/CVE-2020-11981/custom_no_tool",
                "com.docker.compose.service": "airflow-scheduler",
                "com.docker.compose.version": "2.40.3",
                "desktop.docker.io/wsl-distro": "Ubuntu",
                "org.apache.airflow.component": "airflow",
                "org.apache.airflow.distro": "debian",
                "org.apache.airflow.distro.version": "buster",
                "org.apache.airflow.gid": "50000",
                "org.apache.airflow.image": "airflow",
                "org.apache.airflow.module": "airflow",
                "org.apache.airflow.uid": "50000"
            },
            "StopTimeout": 1
        },
        "NetworkSettings": {
            "Bridge": "",
            "SandboxID": "3de4c0b8d04842bf5ff47604556dc43049f1ed21d0b623d4ff474a3e8d326cd6",
            "SandboxKey": "/var/run/docker/netns/3de4c0b8d048",
            "Ports": {},
            "HairpinMode": false,
            "LinkLocalIPv6Address": "",
            "LinkLocalIPv6PrefixLen": 0,
            "SecondaryIPAddresses": null,
            "SecondaryIPv6Addresses": null,
            "EndpointID": "",
            "Gateway": "",
            "GlobalIPv6Address": "",
            "GlobalIPv6PrefixLen": 0,
            "IPAddress": "",
            "IPPrefixLen": 0,
            "IPv6Gateway": "",
            "MacAddress": "",
            "Networks": {
                "custom_no_tool_default": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": [
                        "custom_no_tool-airflow-scheduler-1",
                        "airflow-scheduler"
                    ],
                    "MacAddress": "ba:82:6a:80:b8:73",
                    "DriverOpts": null,
                    "GwPriority": 0,
                    "NetworkID": "8d52c460cc3e4405a33bb754a0bf776f775b179490c623f06b7a08da460f9992",
                    "EndpointID": "59fb89044d404c8906a76d93df70e58a2532fd45e3e2c9ea40d28afc3c34d853",
                    "Gateway": "172.18.0.1",
                    "IPAddress": "172.18.0.5",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "DNSNames": [
                        "custom_no_tool-airflow-scheduler-1",
                        "airflow-scheduler",
                        "b5394411bcee"
                    ]
                }
            }
        },
        "ImageManifestDescriptor": {
            "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
            "digest": "sha256:b67062e5c67906391f7023b1c0ec7b51f8d4d4be1230e96c1e375d98e696f02a",
            "size": 2842,
            "platform": {
                "architecture": "amd64",
                "os": "linux"
            }
        }
    }
]