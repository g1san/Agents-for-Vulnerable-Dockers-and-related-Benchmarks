{
    "desc": "CVE-2020-11978 is a remote code execution vulnerability found in Apache Airflow versions prior to 1.10.11. This vulnerability arises from the default configuration settings in Airflow's default_airflow.cfg, specifically with `load_examples = True` and `auth_backend = airflow.api.auth.backend.default`, which allows unauthenticated access through the experimental REST API. The vulnerability is linked to the example DAGs, particularly `example_trigger_target_dag.py`. Exploitation of this vulnerability allows unauthenticated users to execute arbitrary commands via the publicly accessible experimental API. To mitigate the vulnerability, users should upgrade to version 1.10.11 or later, set `load_examples=False`, and configure `auth_backend=airflow.api.auth.backend.deny_all`. In Airflow versions 2.0.0 and above, the experimental API is disabled by default, providing enhanced security.",
    "attack_type": "remote code execution",
    "services": [
        {
            "name": "apache/airflow",
            "version": [
                "1.10.10"
            ],
            "dependency_type": "HARD",
            "description": "Apache Airflow is the main service where the CVE-2020-11978 vulnerability exists. Versions prior to 1.10.11 are vulnerable."
        },
        {
            "name": "postgres",
            "version": [
                "11"
            ],
            "dependency_type": "SOFT-DB",
            "description": "PostgreSQL is used as the metadata database for Apache Airflow, necessary for storing DAGs and task instances."
        },
        {
            "name": "redis",
            "version": [
                "5.0"
            ],
            "dependency_type": "SOFT-CACHE",
            "description": "Redis is used as the message broker for Apache Airflow, facilitating task communication."
        },
        {
            "name": "python",
            "version": [
                "3.7"
            ],
            "dependency_type": "SOFT",
            "description": "Python is required for running Apache Airflow and its DAGs."
        }
    ],
    "input_tokens": 5139,
    "output_tokens": 881
}